# Documentaci√≥n de Cach√© y Rate Limiting

## üö¶ Rate Limiting

### Configuraci√≥n

El rate limiting est√° configurado con l√≠mites diferentes por endpoint:

- **`/auth/login`**: 5 requests por minuto
- **`/auth/register`**: 3 requests por minuto
- **`/auth/*`** (otros endpoints de auth): 10 requests por minuto
- **Default**: 100 requests por minuto

### Headers de Respuesta

Cada respuesta incluye headers de rate limiting:

- `X-RateLimit-Limit`: L√≠mite m√°ximo de requests
- `X-RateLimit-Remaining`: Requests restantes en la ventana actual
- `X-RateLimit-Reset`: Timestamp de cuando se reinicia la ventana

### Respuesta 429 Too Many Requests

Cuando se excede el l√≠mite, se retorna:

```json
{
  "detail": "Rate limit exceeded. Maximum X requests per Y seconds.",
  "retry_after": 45
}
```

Con headers:
- `Retry-After`: Segundos hasta que se puede hacer otro request

### Identificaci√≥n de Clientes

El rate limiting identifica clientes por:
- **IP address** para usuarios no autenticados
- **User ID** para usuarios autenticados (m√°s preciso)

### Notas de Producci√≥n

- El rate limiting actual usa memoria local (no distribuido)
- Para producci√≥n con m√∫ltiples servidores, considerar usar Redis
- Los contadores se limpian autom√°ticamente cada 5 minutos

---

## üíæ Sistema de Cach√©

### Endpoints con Cach√©

#### Weather Service
- **TTL**: 10 minutos (600 segundos)
- **Clave**: Basada en latitud y longitud
- **Raz√≥n**: Los datos del clima no cambian frecuentemente

#### Recommendations Service
- **TTL**: 1 hora (3600 segundos)
- **Clave**: Basada en hemisferio
- **Raz√≥n**: Las recomendaciones estacionales cambian lentamente

### Uso del Decorador @cached

```python
from app.utils.cache import cached

@cached(ttl=600, key_prefix="weather")
async def get_weather(lat: float, lon: float):
    # Esta funci√≥n se cachea autom√°ticamente
    return weather_data
```

### Gesti√≥n del Cach√©

#### GET /cache/stats
Obtiene estad√≠sticas del cach√©:

```json
{
  "cache": {
    "size": 15,
    "hits": 234,
    "misses": 12,
    "hit_rate": 95.12
  },
  "message": "Cache statistics"
}
```

#### DELETE /cache
Limpia todo el cach√© (requiere autenticaci√≥n).

#### POST /cache/cleanup
Limpia solo entradas expiradas (requiere autenticaci√≥n).

### Caracter√≠sticas

- **TTL (Time To Live)**: Cada entrada tiene un tiempo de expiraci√≥n
- **Limpieza autom√°tica**: Las entradas expiradas se eliminan autom√°ticamente
- **Claves basadas en hash**: Las claves se generan autom√°ticamente desde los argumentos
- **Thread-safe**: Seguro para uso concurrente

### Notas de Producci√≥n

- El cach√© actual es en memoria (no distribuido)
- Para producci√≥n con m√∫ltiples servidores, considerar usar Redis
- El cach√© se limpia autom√°ticamente, pero tambi√©n se puede limpiar manualmente
- Estad√≠sticas disponibles para monitoreo

---

## üîç Request ID Tracking

### Header X-Request-ID

Cada request recibe un ID √∫nico que se incluye en:
- **Header de respuesta**: `X-Request-ID`
- **Logs**: Todos los logs incluyen el `request_id`
- **M√©tricas**: El request_id est√° disponible en el contexto

### Uso

El cliente puede enviar su propio Request ID:

```bash
curl -H "X-Request-ID: my-custom-id" http://api.example.com/endpoint
```

Si no se env√≠a, se genera autom√°ticamente un UUID v4.

### Beneficios

- **Trazabilidad**: Seguir un request a trav√©s de m√∫ltiples servicios
- **Debugging**: Correlacionar logs y errores
- **Monitoreo**: Identificar requests problem√°ticos

### Ejemplo de Log

```json
{
  "timestamp": "2024-01-28T10:30:45.123456",
  "level": "INFO",
  "logger": "app.services.weather_service",
  "message": "Weather data retrieved",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "module": "weather_service",
  "function": "get_weather"
}
```

---

## üìä Monitoreo

### M√©tricas de Rate Limiting

Las m√©tricas de rate limiting se pueden monitorear a trav√©s de:
- Logs cuando se excede el l√≠mite
- Headers en las respuestas
- M√©tricas Prometheus (si se implementan)

### M√©tricas de Cach√©

Las estad√≠sticas del cach√© est√°n disponibles en:
- Endpoint `/cache/stats`
- M√©tricas Prometheus (si se implementan)

### Recomendaciones

1. **Monitorear hit rate**: Un hit rate bajo indica que el cach√© no es efectivo
2. **Monitorear rate limit hits**: Muchos 429 indican l√≠mites muy restrictivos
3. **Ajustar TTLs**: Basado en qu√© tan frecuentemente cambian los datos
4. **Ajustar l√≠mites**: Basado en patrones de uso reales

---

## üîß Configuraci√≥n Futura

### Redis para Rate Limiting

Para producci√≥n distribuida:

```python
from redis import Redis
redis_client = Redis(host='localhost', port=6379)

# Usar Redis para almacenar contadores
```

### Redis para Cach√©

Para producci√≥n distribuida:

```python
import redis
from app.utils.cache import cached

# Usar Redis como backend de cach√©
redis_cache = redis.Redis(host='localhost', port=6379)
```

### Configuraci√≥n desde Variables de Entorno

Agregar a `.env`:

```env
# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_DEFAULT=100
RATE_LIMIT_AUTH_LOGIN=5
RATE_LIMIT_AUTH_REGISTER=3

# Cache
CACHE_ENABLED=true
CACHE_WEATHER_TTL=600
CACHE_RECOMMENDATIONS_TTL=3600
```


